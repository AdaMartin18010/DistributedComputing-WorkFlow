# æ€§èƒ½æµ‹è¯•æ‰§è¡Œè®¡åˆ’ï¼ˆv15.0ï¼‰

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§„åˆ’äº†v15.0ç‰ˆæœ¬çš„æ€§èƒ½æµ‹è¯•å®é™…æ‰§è¡Œå·¥ä½œï¼ŒåŒ…æ‹¬æµ‹è¯•ç¯å¢ƒå‡†å¤‡ã€æµ‹è¯•æ‰§è¡Œå’Œç»“æœåˆ†æã€‚

**å®æ–½æ—¶é—´**ï¼š2024å¹´

**ç›®æ ‡**ï¼šæ‰§è¡Œå®é™…æ€§èƒ½æµ‹è¯•ï¼Œç”ŸæˆçœŸå®çš„æ€§èƒ½æ•°æ®

---

## ğŸ¯ æµ‹è¯•ç›®æ ‡

### æµ‹è¯•èŒƒå›´

1. **ååé‡æµ‹è¯•**ï¼šæµ‹è¯•ç³»ç»Ÿå¤„ç†å·¥ä½œæµçš„èƒ½åŠ›
2. **å»¶è¿Ÿæµ‹è¯•**ï¼šæµ‹è¯•å·¥ä½œæµæ‰§è¡Œçš„å»¶è¿Ÿ
3. **æ•…éšœæ¢å¤æµ‹è¯•**ï¼šæµ‹è¯•ç³»ç»Ÿæ•…éšœæ¢å¤èƒ½åŠ›
4. **å¹¶å‘èƒ½åŠ›æµ‹è¯•**ï¼šæµ‹è¯•ç³»ç»Ÿå¹¶å‘å¤„ç†èƒ½åŠ›
5. **æ‰©å±•æ€§æµ‹è¯•**ï¼šæµ‹è¯•ç³»ç»Ÿæ‰©å±•èƒ½åŠ›
6. **å‹åŠ›æµ‹è¯•**ï¼šæµ‹è¯•ç³»ç»Ÿæé™æ€§èƒ½

---

## ğŸ”§ æµ‹è¯•ç¯å¢ƒå‡†å¤‡

### ç¯å¢ƒè¦æ±‚

**ç¡¬ä»¶è¦æ±‚**ï¼š
- CPUï¼š8æ ¸å¿ƒä»¥ä¸Š
- å†…å­˜ï¼š32GBä»¥ä¸Š
- å­˜å‚¨ï¼šSSD 500GBä»¥ä¸Š
- ç½‘ç»œï¼š1Gbpsä»¥ä¸Š

**è½¯ä»¶è¦æ±‚**ï¼š
- Docker & Docker Compose
- PostgreSQL 15+
- Temporal Server
- Python 3.9+ / Go 1.19+
- æµ‹è¯•å·¥å…·ï¼šk6, wrk, Apache Bench

### ç¯å¢ƒæ­å»ºæ­¥éª¤

```bash
# 1. å¯åŠ¨PostgreSQL
docker-compose up -d postgres

# 2. å¯åŠ¨Temporal Server
docker-compose up -d temporal

# 3. éªŒè¯ç¯å¢ƒ
docker-compose ps
```

---

## ğŸ“Š æµ‹è¯•è„šæœ¬

### 1. ååé‡æµ‹è¯•è„šæœ¬

**Pythonå®ç°**ï¼š

```python
import asyncio
from temporalio.client import Client
from temporalio.worker import Worker
import time
from datetime import timedelta

async def throughput_test():
    """ååé‡æµ‹è¯•"""
    client = await Client.connect("localhost:7233")

    # æµ‹è¯•å‚æ•°
    num_workflows = 1000
    start_time = time.time()

    # å¯åŠ¨å·¥ä½œæµ
    tasks = []
    for i in range(num_workflows):
        task = client.execute_workflow(
            "TestWorkflow",
            f"test-{i}",
            id=f"workflow-{i}",
            task_queue="test-queue"
        )
        tasks.append(task)

    # ç­‰å¾…æ‰€æœ‰å·¥ä½œæµå®Œæˆ
    await asyncio.gather(*tasks)

    end_time = time.time()
    duration = end_time - start_time
    throughput = num_workflows / duration

    print(f"ååé‡æµ‹è¯•ç»“æœï¼š")
    print(f"  å·¥ä½œæµæ•°é‡ï¼š{num_workflows}")
    print(f"  æ€»æ—¶é—´ï¼š{duration:.2f}ç§’")
    print(f"  ååé‡ï¼š{throughput:.2f} workflows/s")

if __name__ == "__main__":
    asyncio.run(throughput_test())
```

---

### 2. å»¶è¿Ÿæµ‹è¯•è„šæœ¬

**Pythonå®ç°**ï¼š

```python
import asyncio
from temporalio.client import Client
import time
import statistics

async def latency_test():
    """å»¶è¿Ÿæµ‹è¯•"""
    client = await Client.connect("localhost:7233")

    # æµ‹è¯•å‚æ•°
    num_workflows = 100
    latencies = []

    for i in range(num_workflows):
        start_time = time.time()

        result = await client.execute_workflow(
            "TestWorkflow",
            f"test-{i}",
            id=f"workflow-{i}",
            task_queue="test-queue"
        )

        end_time = time.time()
        latency = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        latencies.append(latency)

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    mean_latency = statistics.mean(latencies)
    median_latency = statistics.median(latencies)
    p95_latency = sorted(latencies)[int(len(latencies) * 0.95)]
    p99_latency = sorted(latencies)[int(len(latencies) * 0.99)]

    print(f"å»¶è¿Ÿæµ‹è¯•ç»“æœï¼š")
    print(f"  å¹³å‡å»¶è¿Ÿï¼š{mean_latency:.2f}ms")
    print(f"  ä¸­ä½æ•°å»¶è¿Ÿï¼š{median_latency:.2f}ms")
    print(f"  P95å»¶è¿Ÿï¼š{p95_latency:.2f}ms")
    print(f"  P99å»¶è¿Ÿï¼š{p99_latency:.2f}ms")

if __name__ == "__main__":
    asyncio.run(latency_test())
```

---

### 3. æ•…éšœæ¢å¤æµ‹è¯•è„šæœ¬

**Pythonå®ç°**ï¼š

```python
import asyncio
from temporalio.client import Client
import time
import subprocess

async def fault_recovery_test():
    """æ•…éšœæ¢å¤æµ‹è¯•"""
    client = await Client.connect("localhost:7233")

    # å¯åŠ¨å·¥ä½œæµ
    workflow_id = "fault-test-workflow"
    handle = await client.start_workflow(
        "LongRunningWorkflow",
        "test-data",
        id=workflow_id,
        task_queue="test-queue"
    )

    # ç­‰å¾…å·¥ä½œæµè¿è¡Œ
    await asyncio.sleep(5)

    # æ¨¡æ‹Ÿæ•…éšœï¼šåœæ­¢Temporal Server
    print("æ¨¡æ‹Ÿæ•…éšœï¼šåœæ­¢Temporal Server...")
    subprocess.run(["docker-compose", "stop", "temporal"])

    # ç­‰å¾…æ•…éšœæ£€æµ‹
    await asyncio.sleep(10)

    # æ¢å¤æœåŠ¡
    print("æ¢å¤æœåŠ¡ï¼šå¯åŠ¨Temporal Server...")
    subprocess.run(["docker-compose", "start", "temporal"])

    # ç­‰å¾…æœåŠ¡æ¢å¤
    await asyncio.sleep(10)

    # æ£€æŸ¥å·¥ä½œæµçŠ¶æ€
    try:
        result = await handle.result()
        print(f"æ•…éšœæ¢å¤æµ‹è¯•ç»“æœï¼šå·¥ä½œæµæˆåŠŸæ¢å¤ï¼Œç»“æœï¼š{result}")
    except Exception as e:
        print(f"æ•…éšœæ¢å¤æµ‹è¯•ç»“æœï¼šå·¥ä½œæµæ¢å¤å¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")

if __name__ == "__main__":
    asyncio.run(fault_recovery_test())
```

---

### 4. å¹¶å‘èƒ½åŠ›æµ‹è¯•è„šæœ¬

**Pythonå®ç°**ï¼š

```python
import asyncio
from temporalio.client import Client
import time

async def concurrency_test():
    """å¹¶å‘èƒ½åŠ›æµ‹è¯•"""
    client = await Client.connect("localhost:7233")

    # æµ‹è¯•å‚æ•°
    concurrent_workflows = [10, 50, 100, 200, 500, 1000]
    results = []

    for num_concurrent in concurrent_workflows:
        start_time = time.time()

        # å¹¶å‘å¯åŠ¨å·¥ä½œæµ
        tasks = []
        for i in range(num_concurrent):
            task = client.execute_workflow(
                "TestWorkflow",
                f"test-{i}",
                id=f"workflow-{i}",
                task_queue="test-queue"
            )
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰å·¥ä½œæµå®Œæˆ
        await asyncio.gather(*tasks)

        end_time = time.time()
        duration = end_time - start_time

        results.append({
            "concurrent": num_concurrent,
            "duration": duration,
            "throughput": num_concurrent / duration
        })

        print(f"å¹¶å‘æ•°ï¼š{num_concurrent}ï¼Œè€—æ—¶ï¼š{duration:.2f}ç§’ï¼Œååé‡ï¼š{num_concurrent/duration:.2f} workflows/s")

    return results

if __name__ == "__main__":
    asyncio.run(concurrency_test())
```

---

## ğŸ“‹ æµ‹è¯•æ‰§è¡Œè®¡åˆ’

### é˜¶æ®µ1ï¼šç¯å¢ƒå‡†å¤‡ï¼ˆ1å¤©ï¼‰

- [ ] æ­å»ºæµ‹è¯•ç¯å¢ƒ
- [ ] é…ç½®æµ‹è¯•å·¥å…·
- [ ] å‡†å¤‡æµ‹è¯•æ•°æ®
- [ ] éªŒè¯ç¯å¢ƒ

### é˜¶æ®µ2ï¼šåŸºç¡€æµ‹è¯•ï¼ˆ2å¤©ï¼‰

- [ ] æ‰§è¡Œååé‡æµ‹è¯•
- [ ] æ‰§è¡Œå»¶è¿Ÿæµ‹è¯•
- [ ] æ‰§è¡Œæ•…éšœæ¢å¤æµ‹è¯•
- [ ] è®°å½•æµ‹è¯•ç»“æœ

### é˜¶æ®µ3ï¼šé«˜çº§æµ‹è¯•ï¼ˆ2å¤©ï¼‰

- [ ] æ‰§è¡Œå¹¶å‘èƒ½åŠ›æµ‹è¯•
- [ ] æ‰§è¡Œæ‰©å±•æ€§æµ‹è¯•
- [ ] æ‰§è¡Œå‹åŠ›æµ‹è¯•
- [ ] è®°å½•æµ‹è¯•ç»“æœ

### é˜¶æ®µ4ï¼šç»“æœåˆ†æï¼ˆ1å¤©ï¼‰

- [ ] åˆ†ææµ‹è¯•æ•°æ®
- [ ] ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
- [ ] æ›´æ–°æ€§èƒ½åŸºå‡†æµ‹è¯•æ–‡æ¡£

---

## ğŸ“Š æµ‹è¯•æŠ¥å‘Šæ¨¡æ¿

### æµ‹è¯•æŠ¥å‘Šç»“æ„

```markdown
# æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

## æµ‹è¯•æ¦‚è¿°
- æµ‹è¯•æ—¶é—´ï¼š2024å¹´XXæœˆXXæ—¥
- æµ‹è¯•ç¯å¢ƒï¼š...
- æµ‹è¯•å·¥å…·ï¼š...

## æµ‹è¯•ç»“æœ

### ååé‡æµ‹è¯•
- ç»“æœï¼šXXX workflows/s
- åˆ†æï¼š...

### å»¶è¿Ÿæµ‹è¯•
- å¹³å‡å»¶è¿Ÿï¼šXXX ms
- P95å»¶è¿Ÿï¼šXXX ms
- P99å»¶è¿Ÿï¼šXXX ms

### æ•…éšœæ¢å¤æµ‹è¯•
- æ¢å¤æ—¶é—´ï¼šXXX ç§’
- æˆåŠŸç‡ï¼šXXX%

## ç»“è®º
...
```

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### å®Œæˆæ ‡å‡†

1. âœ… æ€§èƒ½æµ‹è¯•æ‰§è¡Œè®¡åˆ’åˆ›å»ºå®Œæˆ
2. â³ æµ‹è¯•ç¯å¢ƒæ­å»ºå®Œæˆ
3. â³ æ‰€æœ‰æµ‹è¯•æ‰§è¡Œå®Œæˆ
4. â³ æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ

### è´¨é‡æ ‡å‡†

- æµ‹è¯•æ–¹æ³•ç§‘å­¦
- æµ‹è¯•æ•°æ®å‡†ç¡®
- æµ‹è¯•æŠ¥å‘Šå®Œæ•´
- æµ‹è¯•ç»“æœå¯å¤ç°

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv15.0

**åˆ›å»ºæ—¶é—´**ï¼š2024å¹´

**ç»´æŠ¤è€…**ï¼šé¡¹ç›®å›¢é˜Ÿ

**çŠ¶æ€**ï¼šâœ… è®¡åˆ’å®Œæˆï¼Œå¾…æ‰§è¡Œ
